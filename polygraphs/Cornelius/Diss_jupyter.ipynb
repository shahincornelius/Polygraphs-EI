{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import networkx as nx\n",
    "import dgl\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polygraphs as pg\n",
    "from polygraphs import hyperparameters as hparams\n",
    "from polygraphs import ops\n",
    "from polygraphs.ops import math, complex\n",
    "from polygraphs.analysis import Processor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(size, seed=None):\n",
    "    \"\"\"\n",
    "    Create a PolyGraph configuration for a complete network\n",
    "    \"\"\"\n",
    "    params = hparams.PolyGraphHyperParameters()\n",
    "\n",
    "    # Initial beliefs are random uniform between 0 and 1\n",
    "    params.init.kind = 'uniform'\n",
    "    # Chance that action B is better than action A\n",
    "    params.epsilon = 0.9\n",
    "\n",
    "    params.network.kind = 'complete'\n",
    "    params.network.size = size\n",
    "    params.network.selfloop = False\n",
    "\n",
    "    params.simulation.steps = 10000\n",
    "    params.logging.enabled = False\n",
    "\n",
    "    # Take snapshots (incl. messages)\n",
    "    params.snapshots.enabled = True\n",
    "    params.snapshots.interval = 100\n",
    "    params.snapshots.messages = True\n",
    "\n",
    "    # Set seed\n",
    "    pg.random()\n",
    "\n",
    "    if seed:\n",
    "        # Explicitly set seed\n",
    "        params.seed = seed\n",
    "        pg.random(params.seed)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete existing data folder for results\n",
    "try:\n",
    "    shutil.rmtree(\"data\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying OconnorWeatherall from common.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OConnorWeatherallOp(ops.core.PolyGraphOp):\n",
    "    \"\"\"\n",
    "    Scientific polarisation (O'Connor & Weatherall, 2018)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, graph, params):\n",
    "        super().__init__(graph, params)\n",
    "\n",
    "        # Multiplier that captures how quickly agents become uncertain about\n",
    "        # the evidence of their peers as their beliefs diverge.\n",
    "        self.mistrust = params.mistrust\n",
    "\n",
    "        # Whether to discount evidence with unti-updating or not\n",
    "        self.antiupdating = params.antiupdating\n",
    "\n",
    "    def filterfn(self):\n",
    "        \"\"\"\n",
    "        # Filters out edges whose source has no evidence to report\n",
    "        \"\"\"\n",
    "\n",
    "        def function(edges):\n",
    "            return torch.gt(edges.src[\"payoffs\"][:, 1], 0.0)\n",
    "\n",
    "        return function\n",
    "\n",
    "    def messagefn(self):\n",
    "        \"\"\"\n",
    "        Message function\n",
    "        \"\"\"\n",
    "\n",
    "        def function(edges):\n",
    "            return {\"payoffs\": edges.src[\"payoffs\"], \"beliefs\": edges.src[\"beliefs\"]}\n",
    "\n",
    "        return function\n",
    "\n",
    "    def _distancefn(self, delta):\n",
    "        \"\"\"\n",
    "        Distance function\n",
    "        \"\"\"\n",
    "        return delta * self.mistrust\n",
    "\n",
    "    def reducefn(self):\n",
    "        \"\"\"\n",
    "        Reduce function\n",
    "        \"\"\"\n",
    "\n",
    "        def function(nodes):\n",
    "            # Log probability of successful trials\n",
    "            logits = nodes.data[\"logits\"]\n",
    "            # Prior, P(H) (aka. belief)\n",
    "            prior = nodes.data[\"beliefs\"]\n",
    "\n",
    "            attrs = vars(nodes)\n",
    "            print(', '.join(\"%s: %s\" % item for item in attrs.items()))\n",
    "            # Number of nodes and number of neighbours per node (incoming messages)\n",
    "            _, neighbours = nodes.mailbox[\"beliefs\"].shape\n",
    "            for i in range(neighbours):\n",
    "                # A node receives evidence E from its i-th neighbour, say Jill,\n",
    "                # denoting the number of successful trials and the total number\n",
    "                # of trials she observed\n",
    "                values = nodes.mailbox[\"payoffs\"][:, i, 0]\n",
    "                trials = nodes.mailbox[\"payoffs\"][:, i, 1]\n",
    "\n",
    "                # Evidence, E\n",
    "                evidence = math.Evidence(logits, values, trials)\n",
    "\n",
    "                # The difference in belief between an agent\n",
    "                # and its i-th neighbour\n",
    "                delta = torch.abs(prior - nodes.mailbox[\"beliefs\"][:, i])\n",
    "\n",
    "                # Compute belief that the evidence E is real, P(E)(d)\n",
    "                if self.antiupdating:\n",
    "                    certainty = torch.max(\n",
    "                        1.0\n",
    "                        - self._distancefn(delta)\n",
    "                        * (1.0 - math.marginal(prior, evidence)),\n",
    "                        torch.zeros((len(nodes),)),\n",
    "                    )\n",
    "                else:\n",
    "                    # Consider an agent u and one of its neighbours, v. As\n",
    "                    # beliefs between u and v diverge (delta towards 1),\n",
    "                    # agent u simply ignores the evidence of agent v.\n",
    "                    #\n",
    "                    # If delta becomes 1, uncertainty ~ marginal. In other\n",
    "                    # words, agent u's belief remains unchanged in light of\n",
    "                    # agent v's evidence.\n",
    "                    #\n",
    "                    # The multiplier simply determines how far apart beliefs\n",
    "                    # have to become before agent u begins to ignore the\n",
    "                    # evidence of its neighbour, v (since delta never becomes 1)\n",
    "                    certainty = 1.0 - torch.min(\n",
    "                        torch.ones((len(nodes),)), self._distancefn(delta)\n",
    "                    ) * (1.0 - math.marginal(prior, evidence))\n",
    "\n",
    "                # Compute posterior belief, in light of soft uncertainty\n",
    "                posterior = math.jeffrey(prior, evidence, certainty)\n",
    "\n",
    "                # Consider next neighbour\n",
    "                prior = posterior\n",
    "\n",
    "            # Return posterior beliefs for each neighbour\n",
    "            return {\"beliefs\": posterior}\n",
    "\n",
    "        return function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Processor(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_file_path</th>\n",
       "      <th>hd5_file_path</th>\n",
       "      <th>config_json_path</th>\n",
       "      <th>trials</th>\n",
       "      <th>network_size</th>\n",
       "      <th>network_kind</th>\n",
       "      <th>op</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>steps</th>\n",
       "      <th>duration</th>\n",
       "      <th>action</th>\n",
       "      <th>undefined</th>\n",
       "      <th>converged</th>\n",
       "      <th>polarized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/ow/1.bin</td>\n",
       "      <td>data/ow/1.hd5</td>\n",
       "      <td>data/ow/configuration.json</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>complete_grouped</td>\n",
       "      <td>Epistemic_Injustice</td>\n",
       "      <td>0.001</td>\n",
       "      <td>219.0</td>\n",
       "      <td>17.762682</td>\n",
       "      <td>B</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/bg/1.bin</td>\n",
       "      <td>data/bg/1.hd5</td>\n",
       "      <td>data/bg/configuration.json</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>complete</td>\n",
       "      <td>BalaGoyalOp</td>\n",
       "      <td>0.001</td>\n",
       "      <td>207.0</td>\n",
       "      <td>13.152652</td>\n",
       "      <td>B</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bin_file_path  hd5_file_path            config_json_path  trials  \\\n",
       "0  data/ow/1.bin  data/ow/1.hd5  data/ow/configuration.json    10.0   \n",
       "1  data/bg/1.bin  data/bg/1.hd5  data/bg/configuration.json    10.0   \n",
       "\n",
       "   network_size      network_kind                   op  epsilon  steps  \\\n",
       "0        1000.0  complete_grouped  Epistemic_Injustice    0.001  219.0   \n",
       "1        1000.0          complete          BalaGoyalOp    0.001  207.0   \n",
       "\n",
       "    duration action undefined converged polarized  \n",
       "0  17.762682      B     False      True     False  \n",
       "1  13.152652      B     False      True     False  "
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='iteration'>"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "x.beliefs[1].groupby(\"iteration\").mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='iteration'>"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#x.beliefs[1].groupby(\"iteration\").mean().plot()\n",
    "x.beliefs[0].groupby(\"iteration\").mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlignedOp(ops.BalaGoyalOp):\n",
    "    \"\"\"\n",
    "    Baseclass for Aligned Ops that uses Jeffreys rule\n",
    "\n",
    "    Unreliable networks, Part 2\n",
    "\n",
    "    There are two types of nodes, reliable and unreliable ones.\n",
    "\n",
    "    Upon receipt, all nodes apply Jeffrey's rule.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, graph, params):\n",
    "        super().__init__(graph, params)\n",
    "        # Store network reliability in the graph\n",
    "        #graph.ndata[\"reliability\"] = self._reliability.to(device=self._device)\n",
    "\n",
    "    def messagefn(self):\n",
    "        \"\"\"\n",
    "        Message function\n",
    "        \"\"\"\n",
    "\n",
    "        def function(edges):\n",
    "            return {\n",
    "                \"payoffs\": edges.src[\"payoffs\"],\n",
    "                \"group\": edges.src[\"group\"],\n",
    "            }\n",
    "\n",
    "        return function\n",
    "\n",
    "    def reducefn(self):\n",
    "        \"\"\"\n",
    "        Reduce function\n",
    "        \"\"\"\n",
    "\n",
    "        def function(nodes):\n",
    "            # Log probability of successful trials\n",
    "            logits = nodes.data[\"logits\"]\n",
    "            # Prior, P(H) (aka. belief)\n",
    "            prior = nodes.data[\"beliefs\"]\n",
    "\n",
    "            # Number of nodes and number of neighbours per node (incoming messages)\n",
    "            _, neighbours = nodes.mailbox[\"group\"].shape\n",
    "            for i in range(neighbours):\n",
    "                # A node receives evidence E from its i-th neighbour, say Jill,\n",
    "                # denoting the number of successful trials and the total number\n",
    "                # of trials she observed\n",
    "                values = nodes.mailbox[\"payoffs\"][:, i, 0]\n",
    "                trials = nodes.mailbox[\"payoffs\"][:, i, 1]\n",
    "\n",
    "                # Evidence, E\n",
    "                evidence = math.Evidence(logits, values, trials)\n",
    "\n",
    "                # Get i-th neighbour reliability\n",
    "                reliability = 1#nodes.mailbox[\"reliability\"][:, i]\n",
    "\n",
    "                # log.info(f\"Neighbour {i:2d}: reliability {reliability}\")\n",
    "\n",
    "                # Compute posterior belief, in light of soft uncertainty\n",
    "                # (i.e., network unreliability)\n",
    "                posterior = math.jeffrey(prior, evidence, reliability)\n",
    "\n",
    "                # Consider next neighbour\n",
    "                prior = posterior\n",
    "\n",
    "            # Return posterior beliefs for each neighbour\n",
    "            return {\"beliefs\": posterior}\n",
    "\n",
    "        return function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OConnorWeatherallOp(ops.core.PolyGraphOp):\n",
    "    \"\"\"\n",
    "    Scientific polarisation (O'Connor & Weatherall, 2018)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, graph, params):\n",
    "        super().__init__(graph, params)\n",
    "\n",
    "        # Multiplier that captures how quickly agents become uncertain about\n",
    "        # the evidence of their peers as their beliefs diverge.\n",
    "        self.mistrust = params.mistrust\n",
    "\n",
    "        # Whether to discount evidence with unti-updating or not\n",
    "        self.antiupdating = params.antiupdating\n",
    "\n",
    "    def filterfn(self):\n",
    "        \"\"\"\n",
    "        # Filters out edges whose source has no evidence to report\n",
    "        \"\"\"\n",
    "\n",
    "        def function(edges):\n",
    "            return torch.gt(edges.src[\"payoffs\"][:, 1], 0.0)\n",
    "\n",
    "        return function\n",
    "\n",
    "    def messagefn(self):\n",
    "        \"\"\"\n",
    "        Message function\n",
    "        \"\"\"\n",
    "\n",
    "        def function(edges):\n",
    "            return {\"payoffs\": edges.src[\"payoffs\"], \"beliefs\": edges.src[\"beliefs\"]}\n",
    "\n",
    "        return function\n",
    "\n",
    "    def _distancefn(self, delta):\n",
    "        \"\"\"\n",
    "        Distance function\n",
    "        \"\"\"\n",
    "        return delta * self.mistrust\n",
    "\n",
    "    def reducefn(self):\n",
    "        \"\"\"\n",
    "        Reduce function\n",
    "        \"\"\"\n",
    "\n",
    "        def function(nodes):\n",
    "            # Log probability of successful trials\n",
    "            logits = nodes.data[\"logits\"]\n",
    "            # Prior, P(H) (aka. belief)\n",
    "            prior = nodes.data[\"beliefs\"]\n",
    "\n",
    "            # Number of nodes and number of neighbours per node (incoming messages)\n",
    "            _, neighbours = nodes.mailbox[\"beliefs\"].shape\n",
    "            for i in range(neighbours):\n",
    "                # A node receives evidence E from its i-th neighbour, say Jill,\n",
    "                # denoting the number of successful trials and the total number\n",
    "                # of trials she observed\n",
    "                values = nodes.mailbox[\"payoffs\"][:, i, 0]\n",
    "                trials = nodes.mailbox[\"payoffs\"][:, i, 1]\n",
    "\n",
    "                # Evidence, E\n",
    "                evidence = math.Evidence(logits, values, trials)\n",
    "\n",
    "                # The difference in belief between an agent\n",
    "                # and its i-th neighbour\n",
    "                #delta = torch.abs(prior - nodes.mailbox[\"beliefs\"][:, i])\n",
    "\n",
    "                # Compute belief that the evidence E is real, P(E)(d)\n",
    "                if self.antiupdating:\n",
    "                    certainty = 1\n",
    "                \n",
    "                else:\n",
    "                    # Consider an agent u and one of its neighbours, v. As\n",
    "                    # beliefs between u and v diverge (delta towards 1),\n",
    "                    # agent u simply ignores the evidence of agent v.\n",
    "                    #\n",
    "                    # If delta becomes 1, uncertainty ~ marginal. In other\n",
    "                    # words, agent u's belief remains unchanged in light of\n",
    "                    # agent v's evidence.\n",
    "                    #\n",
    "                    # The multiplier simply determines how far apart beliefs\n",
    "                    # have to become before agent u begins to ignore the\n",
    "                    # evidence of its neighbour, v (since delta never becomes 1)\n",
    "                    certainty = 1# - torch.min(\n",
    "                        #torch.ones((len(nodes),)), self._distancefn(delta)\n",
    "                    #) * (1.0 - math.marginal(prior, evidence))\n",
    "\n",
    "                # Compute posterior belief, in light of soft uncertainty\n",
    "                posterior = math.jeffrey(prior, evidence, certainty)\n",
    "\n",
    "                # Consider next neighbour\n",
    "                prior = posterior\n",
    "\n",
    "            # Return posterior beliefs for each neighbour\n",
    "            return {\"beliefs\": posterior}\n",
    "\n",
    "        return function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = complete(16, seed=12345)\n",
    "params.simulation.results = \"data/ow\"\n",
    "_ = pg.simulate(params, op=AlignedOp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prejudice_params(size, groups, prejudiced_certainty, non_prejudiced_certainty, seed=None):\n",
    "    \"\"\"\n",
    "    Create a PolyGraph configuration for a grouped complete network\n",
    "    \"\"\"\n",
    "    params = hparams.PolyGraphHyperParameters()\n",
    "\n",
    "    # Setting number of groups\n",
    "    params.network.groups = groups\n",
    "\n",
    "    # Setting prejudice and non-prejudice certainty for Jeffrey's Rule\n",
    "    params.mistrust = prejudiced_certainty\n",
    "    params.trust = non_prejudiced_certainty\n",
    "\n",
    "    # Initial beliefs are random uniform between 0 and 1\n",
    "    params.init.kind = 'uniform'\n",
    "    # Chance that action B is better than action A\n",
    "    params.epsilon = 0.001\n",
    "\n",
    "    params.network.kind = 'complete_grouped'\n",
    "    params.network.size = size\n",
    "    params.network.selfloop = True\n",
    "\n",
    "    params.simulation.steps = 20000\n",
    "    params.logging.enabled = False\n",
    "\n",
    "    # Take snapshots (incl. messages)\n",
    "    params.snapshots.enabled = True\n",
    "    params.snapshots.interval = 100\n",
    "    params.snapshots.messages = True\n",
    "\n",
    "\n",
    "    # Set seed\n",
    "    pg.random()\n",
    "\n",
    "    if seed:\n",
    "        # Explicitly set seed\n",
    "        params.seed = seed\n",
    "        pg.random(params.seed)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Epistemic_Injustice(ops.BalaGoyalOp):\n",
    "    \"\"\"\n",
    "   \n",
    "    Upon receipt, all nodes apply Jeffrey's rule.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, graph, params):\n",
    "        super().__init__(graph, params)\n",
    "        \n",
    "\n",
    "        # Define list of unique groups from node features and store as instance attribute\n",
    "        self.groups = torch.unique(graph.ndata['group']).tolist()\n",
    "\n",
    "         # Create group masks\n",
    "        self.group_masks = {}\n",
    "        for group in self.groups:\n",
    "            self.group_masks[group] = (graph.ndata['group'] == group)\n",
    "        # print((graph.ndata['group']))\n",
    "        # print(self.group_masks[0])\n",
    "\n",
    "    def messagefn(self):\n",
    "        \"\"\"\n",
    "        Message function\n",
    "        \"\"\"\n",
    "\n",
    "        def function(edges):\n",
    "            return {\n",
    "                \"payoffs\": edges.src[\"payoffs\"],\n",
    "                \"group\": edges.src[\"group\"],\n",
    "            }\n",
    "\n",
    "        return function\n",
    "\n",
    "    def reducefn(self):\n",
    "        \"\"\"\n",
    "        Reduce function\n",
    "        \"\"\"\n",
    "\n",
    "        def function(nodes):\n",
    "            # Log probability of successful trials\n",
    "            logits = nodes.data[\"logits\"]\n",
    "            # Prior, P(H) (aka. belief)\n",
    "            prior = nodes.data[\"beliefs\"]\n",
    "\n",
    "    \n",
    "            for recipient_group in self.groups:\n",
    "                group_mask = self.group_masks[recipient_group]\n",
    "                \n",
    "                for sender_group in self.groups:\n",
    "                    sender_mask = (nodes.mailbox[\"group\"][group_mask] == sender_group)\n",
    "                    # print(f\"sender group {sender_group}\")\n",
    "                    # print(nodes.mailbox[\"payoffs\"][group_mask][sender_mask])\n",
    "\n",
    "                    sender_group_values = torch.sum(nodes.mailbox[\"payoffs\"][group_mask][sender_mask][:, 0])\n",
    "                    sender_group_trials = torch.sum(nodes.mailbox[\"payoffs\"][group_mask][sender_mask][:, 1])\n",
    "\n",
    "                    # Evidence, E\n",
    "                    evidence = math.Evidence(logits, sender_group_values, sender_group_trials)\n",
    "\n",
    "                    # Define group 0 as prejudiced-against and group 1 as prejudiced\n",
    "                    if sender_group == 0 and recipient_group == 1:\n",
    "                        # Define arbitrary amount of evidence-discounting performed by prejudiced nodes\n",
    "                        certainty = 0\n",
    "                    else:\n",
    "                        certainty = 1\n",
    "                    \n",
    "                    # Compute posterior belief\n",
    "                    posterior = math.jeffrey(prior, evidence, certainty)\n",
    "\n",
    "                    # Consider next sender group\n",
    "                    prior = posterior\n",
    "\n",
    "            # Return posterior beliefs\n",
    "            return {\"beliefs\": posterior}\n",
    "\n",
    "        return function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Epistemic_Injustice_Checkpoint(ops.BalaGoyalOp):\n",
    "#     \"\"\"\n",
    "   \n",
    "#     Upon receipt, all nodes apply Jeffrey's rule.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, graph, params):\n",
    "#         super().__init__(graph, params)\n",
    "        \n",
    "\n",
    "#         # Define list of unique groups from node features and store as instance attribute\n",
    "#         self.groups = torch.unique(graph.ndata['group']).tolist()\n",
    "\n",
    "#          # Create group masks\n",
    "#         self.group_masks = {}\n",
    "#         for group in self.groups:\n",
    "#             self.group_masks[group] = (graph.ndata['group'] == group)\n",
    "#         # print((graph.ndata['group']))\n",
    "#         # print(self.group_masks[0])\n",
    "\n",
    "#     def messagefn(self):\n",
    "#         \"\"\"\n",
    "#         Message function\n",
    "#         \"\"\"\n",
    "\n",
    "#         def function(edges):\n",
    "#             return {\n",
    "#                 \"payoffs\": edges.src[\"payoffs\"],\n",
    "#                 \"group\": edges.src[\"group\"],\n",
    "#             }\n",
    "\n",
    "#         return function\n",
    "\n",
    "#     def reducefn(self):\n",
    "#         \"\"\"\n",
    "#         Reduce function\n",
    "#         \"\"\"\n",
    "\n",
    "#         def function(nodes):\n",
    "#             # Log probability of successful trials\n",
    "#             logits = nodes.data[\"logits\"]\n",
    "#             # Prior, P(H) (aka. belief)\n",
    "#             prior = nodes.data[\"beliefs\"]\n",
    "\n",
    "    \n",
    "#             for recipient_group in self.groups:\n",
    "#                 group_mask = self.group_masks[recipient_group]\n",
    "                \n",
    "#                 for sender_group in self.groups:\n",
    "#                     sender_mask = (nodes.mailbox[\"group\"][group_mask] == sender_group)\n",
    "#                     # print(f\"sender group {sender_group}\")\n",
    "#                     # print(nodes.mailbox[\"payoffs\"][group_mask][sender_mask])\n",
    "\n",
    "#                     sender_group_values = torch.sum(nodes.mailbox[\"payoffs\"][group_mask][sender_mask][:, 0])\n",
    "#                     sender_group_trials = torch.sum(nodes.mailbox[\"payoffs\"][group_mask][sender_mask][:, 1])\n",
    "\n",
    "#                     # Evidence, E\n",
    "#                     evidence = math.Evidence(logits, sender_group_values, sender_group_trials)\n",
    "\n",
    "#                     # Define group 0 as prejudiced-against and group 1 as prejudiced\n",
    "#                     if sender_group == 0 and recipient_group == 1:\n",
    "#                         # Define arbitrary amount of evidence-discounting performed by prejudiced nodes\n",
    "#                         certainty = 0\n",
    "#                     else:\n",
    "#                         certainty = 1\n",
    "                    \n",
    "#                     # Compute posterior belief\n",
    "#                     posterior = math.jeffrey(prior, evidence, certainty)\n",
    "\n",
    "#                     # Consider next sender group\n",
    "#                     prior = posterior\n",
    "\n",
    "#             # Return posterior beliefs\n",
    "#             return {\"beliefs\": posterior}\n",
    "\n",
    "#         return function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Epistemic_Injustice(ops.BalaGoyalOp):\n",
    "    \"\"\"\n",
    "   \n",
    "    Upon receipt, all nodes apply Jeffrey's rule.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, graph, params):\n",
    "        super().__init__(graph, params)\n",
    "        \n",
    "        # Grabbing list of group labels\n",
    "        self.groups = torch.unique(graph.ndata['group']).tolist()\n",
    "        \n",
    "        # Grabbing certainty value for Jeffrey's Rule where testimonial injustice occurs\n",
    "        self.default_certainty = params.trust\n",
    "\n",
    "        # Grabbing certainty values for Jeffrey's Rule where testimonial injustice does not occur\n",
    "        self.prejudice_amount = params.mistrust\n",
    "\n",
    "        #print(\"Total:\",graph.ndata[\"group\"])\n",
    "\n",
    "        #  # Create group masks\n",
    "        # self.group_masks = {}\n",
    "\n",
    "        # for group in self.groups:\n",
    "        #     self.group_masks[group] = (graph.ndata['group'] == group)\n",
    "        # # print((graph.ndata['group']))\n",
    "        # # print(self.group_masks[0])\n",
    "\n",
    "    def messagefn(self):\n",
    "        \"\"\"\n",
    "        Message function\n",
    "        \"\"\"\n",
    "\n",
    "        def function(edges):\n",
    "            return {\n",
    "                \"payoffs\": edges.src[\"payoffs\"],\n",
    "                \"group\": edges.src[\"group\"],\n",
    "            }\n",
    "\n",
    "        return function\n",
    "\n",
    "    def reducefn(self):\n",
    "        \"\"\"\n",
    "        Reduce function\n",
    "        \"\"\"\n",
    "\n",
    "        def function(nodes):\n",
    "            # Log probability of successful trials\n",
    "            logits = nodes.data[\"logits\"]\n",
    "            # Prior, P(H) (aka. belief)\n",
    "            prior = nodes.data[\"beliefs\"]\n",
    "            # Current Node's group\n",
    "            recipient_group = nodes.data[\"group\"]\n",
    "\n",
    "            #print(\"Recipients:\",recipient_group)\n",
    "            ##print(\"Mailbox group:\",nodes.mailbox[\"group\"])\n",
    "            ##print(\"All payoffs:\",nodes.mailbox[\"payoffs\"])\n",
    "\n",
    "            # Duplicate each node's group label across columns for every neighbor\n",
    "            # recipient_group_expanded = recipient_group.unsqueeze(1).expand(-1, nodes.mailbox[\"group\"].shape[1])\n",
    "\n",
    "            #print(\"expanded:\",recipient_group_expanded)\n",
    "            # print(\"Mailbox Groups\")\n",
    "            #print(\"mailbox group:\",nodes.mailbox[\"group\"])\n",
    "            # print(\"mailbox payoffs shape:\",nodes.mailbox[\"payoffs\"].shape)\n",
    "            #print(\"shape of nodes.data[group]\",nodes.data[\"group\"].shape)\n",
    "            \n",
    "            default_certainty = self.default_certainty\n",
    "            prejudice_amount = self.prejudice_amount # Amount of discrediting for instances of testimonial injustice\n",
    "\n",
    "            for group in self.groups:\n",
    "                group_mask = (nodes.mailbox[\"group\"] == group)\n",
    "            \n",
    "                masked_payoffs = nodes.mailbox[\"payoffs\"] * group_mask.unsqueeze(-1).float()\n",
    "                \n",
    "                #print(\"Iterating over group:\",group,)\n",
    "                ##print(\"Masked Payoffs:\",masked_payoffs)\n",
    "\n",
    "                    # TOTAL CERTAINTY TENSOR, PROBABLY NOT NEEDED\n",
    "                    # certainty_bin = (nodes.mailbox[\"group\"] == 0) & (recipient_group_expanded == 1)\n",
    "                    # #print(\"certainty\",certainty_bin)\n",
    "\n",
    "                    # # Define inverse mask\n",
    "                    # certainty_bin_inv = ~certainty_bin\n",
    "                    # #print(\"certainty inverse\",certainty_bin_inv)\n",
    "\n",
    "                    # # Set certainty in case of prejudice\n",
    "                    # prejudiced_certainty = certainty_bin * 0.5 # Amount of discrediting, max: 0, min: 1\n",
    "\n",
    "                    # # Set certainity for all other cases\n",
    "                    # non_prejudiced_certainty = certainty_bin_inv * .9\n",
    "                \n",
    "                # Define nodes belonging to group 0 as prejudiced-against\n",
    "                # (The certainty value for instances of testimonial injustice is applied only if the payoffs are sent by group 0)\n",
    "                if group == 0:\n",
    "\n",
    "                    # Define nodes belonging to group 1 as prejudiced\n",
    "                    prejudiced_nodes_mask = (recipient_group == 1)\n",
    "\n",
    "                    # Define all other nodes as non-prejudiced\n",
    "                    non_prejudiced_nodes_mask = ~prejudiced_nodes_mask\n",
    "\n",
    "                    # print(recipient_group)\n",
    "                    # print(\"Prejudiced nodes:\",prejudiced_nodes_mask)\n",
    "                    # print(non_prejudiced_nodes_mask)\n",
    "\n",
    "                    # Set certainty in case of prejudice\n",
    "                    prejudiced_certainty = prejudiced_nodes_mask * prejudice_amount\n",
    "\n",
    "                    # Set certainity for all other cases\n",
    "                    non_prejudiced_certainty = non_prejudiced_nodes_mask * default_certainty\n",
    "\n",
    "                    # Combine certainty tensors\n",
    "                    certainty = prejudiced_certainty + non_prejudiced_certainty\n",
    "\n",
    "                    #print(\"Combined certainty:\",certainty)\n",
    "\n",
    "                    # Sum values for all neighbors belonging to current sender group\n",
    "                    sender_group_values = torch.sum(masked_payoffs[:, :, 0], dim=1)\n",
    "                    ##print(\"Masked values sum:\",sender_group_values)\n",
    "\n",
    "                    # Sum trials for all neighbors belonging to current sender group\n",
    "                    sender_group_trials = torch.sum(masked_payoffs[:, :, 1], dim=1)\n",
    "                    #print(\"Masked trials sum:\",sender_group_trials)\n",
    "\n",
    "                    # Evidence, E\n",
    "                    evidence = math.Evidence(logits, sender_group_values, sender_group_trials)\n",
    "                    # print(\"Evidence:\",evidence)\n",
    "\n",
    "                    # Apply Jeffrey's Rule to all nodes\n",
    "                    posterior = math.jeffrey(prior, evidence, certainty)\n",
    "\n",
    "                    # Consider next sender group\n",
    "                    prior = posterior\n",
    "\n",
    "\n",
    "                else:\n",
    "\n",
    "                    # Create a tensor with a 1 for each node in the network \n",
    "                    recipient_ones = torch.ones_like(recipient_group)\n",
    "                    # Multiply 1's by default certainty\n",
    "                    certainty = recipient_ones * default_certainty\n",
    "                    #print(\"Combined certainty:\",certainty)\n",
    "                    \n",
    "                    # Sum values for all neighbors belonging to current sender group\n",
    "                    sender_group_values = torch.sum(masked_payoffs[:, :, 0], dim=1)\n",
    "                    #print(\"masked values sum:\",sender_group_values)\n",
    "\n",
    "                    # Sum trials for all neighbors belonging to current sender group\n",
    "                    sender_group_trials = torch.sum(masked_payoffs[:, :, 1], dim=1)\n",
    "                    # print(\"masked trials sum:\",sender_group_trials)\n",
    "\n",
    "                    # Evidence, E\n",
    "                    evidence = math.Evidence(logits, sender_group_values, sender_group_trials)\n",
    "                    # print(\"Evidence:\",evidence)\n",
    "\n",
    "                    # Apply Jeffrey's Rule to all nodes\n",
    "                    posterior = math.jeffrey(prior, evidence, certainty)\n",
    "                    \n",
    "                    # Consider next sender group\n",
    "                    prior = posterior\n",
    "\n",
    "            # Return posterior beliefs\n",
    "            return {\"beliefs\": posterior}\n",
    "\n",
    "        return function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete existing data folder for results\n",
    "try:\n",
    "    shutil.rmtree(\"data\")\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " INFO polygraphs> Sim #0001:   4969 steps   41.16s; action: B undefined: 0 converged: 1 polarized: 0 \n"
     ]
    }
   ],
   "source": [
    "params = prejudice_params(30, 2, 1, 1, seed=12345) #(size, groups, prejudiced_certainty, non_prejudiced_certainty, seed)\n",
    "params.simulation.results = \"data/ow-25\"\n",
    "_ = pg.simulate(params, op=AlignedOp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipients: tensor([0, 1, 1, 0, 1, 0])\n",
      " INFO polygraphs> Sim #0001:      1 steps    0.01s; action: ? undefined: 0 converged: 0 polarized: 0 \n"
     ]
    }
   ],
   "source": [
    "# Delete existing data folder for results\n",
    "try:\n",
    "    shutil.rmtree(\"group_test\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "params = prejudice_params(6, 2, 1, 1, seed=123484) #(size, groups, prejudiced_certainty, non_prejudiced_certainty, seed)\n",
    "params.simulation.results = \"group_test\"\n",
    "_ = pg.simulate(params, op=EpistemicInjusticeOp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 2, 1]\n",
      "[1, 2, 0]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      "[2, 0, 1]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[2, 1, 0]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2]\n",
      "[1, 2, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 1, 0]\n",
      "[2, 0, 1]\n",
      "[1, 0, 2]\n",
      "[0, 2, 1]\n",
      "[2, 0, 1]\n",
      "[0, 1, 2]\n",
      "[2, 0, 1]\n",
      "[1, 2, 0]\n",
      " INFO polygraphs> Sim #0001:   2663 steps    7.84s; action: B undefined: 0 converged: 1 polarized: 0 \n"
     ]
    }
   ],
   "source": [
    "params = prejudice_params(64, 3, 1, 1, seed=12345) #(size, groups, prejudiced_certainty, non_prejudiced_certainty, seed)\n",
    "params.simulation.results = \"data/loop\"\n",
    "_ = pg.simulate(params, op=EpistemicInjusticeOp_Shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " INFO polygraphs> Sim #0001:   5673 steps   53.66s; action: B undefined: 0 converged: 1 polarized: 0 \n"
     ]
    }
   ],
   "source": [
    "params = prejudice_params(30, 2, 1, 1, seed=12345) #(size, groups, prejudiced_certainty, non_prejudiced_certainty, seed)\n",
    "params.simulation.results = \"data/ow-5\"\n",
    "_ = pg.simulate(params, op=OConnorWeatherallOp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " INFO polygraphs> Sim #0001:   5676 steps   11.14s; action: B undefined: 0 converged: 1 polarized: 0 \n"
     ]
    }
   ],
   "source": [
    "params = prejudice_params(30, 2, 1, 1, seed=12345) #(size, groups, prejudiced_certainty, non_prejudiced_certainty, seed)\n",
    "params.simulation.results = \"data/ow-6\"\n",
    "_ = pg.simulate(params, op=Epistemic_Injustice_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " INFO polygraphs> Sim #0001:   5302 steps   11.38s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4820 steps    9.26s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4723 steps    9.21s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  11447 steps   22.27s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   9806 steps   19.86s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   9708 steps   18.83s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  10819 steps   21.34s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   8451 steps   17.37s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   8986 steps   17.14s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   8298 steps   16.00s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  10840 steps   22.33s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   5570 steps   10.63s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2952 steps    5.70s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3878 steps    7.39s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  10783 steps   21.21s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3054 steps    7.00s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6239 steps   12.18s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3024 steps    5.73s; action: A undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3681 steps    7.01s; action: A undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   5990 steps   11.48s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2174 steps    4.83s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  20000 steps   39.29s; action: ? undefined: 0 converged: 0 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  10004 steps   19.31s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   7958 steps   16.87s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  13566 steps   26.09s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3541 steps    6.75s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  10757 steps   21.65s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4932 steps    9.90s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4455 steps    8.80s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4986 steps   10.07s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   9172 steps   17.43s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6069 steps   12.52s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  12460 steps   24.28s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4259 steps    8.08s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   7929 steps   15.16s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4915 steps   10.57s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   9093 steps   17.78s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3006 steps    5.69s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   9367 steps   18.12s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  13694 steps   27.22s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6658 steps   13.34s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2903 steps    5.48s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   7277 steps   13.85s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   5143 steps   10.99s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4334 steps    8.32s; action: A undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  10379 steps   20.53s; action: A undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  20000 steps   39.38s; action: ? undefined: 0 converged: 0 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   7133 steps   14.11s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   5260 steps   10.20s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4116 steps    7.87s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6912 steps   13.17s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   8149 steps   16.46s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   8344 steps   16.35s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6495 steps   12.48s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4151 steps    7.86s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   7034 steps   14.92s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4171 steps    8.14s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   7411 steps   14.65s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   5995 steps   11.35s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   8944 steps   18.22s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  11295 steps   21.62s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2612 steps    5.00s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   7653 steps   15.38s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3826 steps    8.48s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4349 steps    8.23s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3733 steps    7.73s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6925 steps   13.96s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4968 steps   10.55s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3877 steps    8.95s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  17430 steps   35.93s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6398 steps   13.20s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  10236 steps   22.46s; action: A undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  15912 steps   32.98s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   8077 steps   17.64s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  12408 steps   26.80s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4472 steps    9.12s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1670 steps    3.35s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4715 steps    9.78s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6817 steps   14.21s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4010 steps    9.31s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  17187 steps   36.51s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   8472 steps   17.45s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6707 steps   14.73s; action: A undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   5536 steps   11.40s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  12779 steps   25.04s; action: A undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   8219 steps   15.25s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   7209 steps   14.65s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4073 steps    9.27s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   5823 steps   11.22s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6800 steps   12.48s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  20000 steps   36.99s; action: ? undefined: 0 converged: 0 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3627 steps    8.17s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2874 steps    5.49s; action: A undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  20000 steps   37.15s; action: ? undefined: 0 converged: 0 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  10421 steps   20.79s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   9004 steps   16.66s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4523 steps    8.39s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   7285 steps   13.74s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6891 steps   13.23s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  11365 steps   22.28s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   5302 steps   10.88s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4820 steps    9.90s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4723 steps    9.62s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  11447 steps   24.04s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   9806 steps   21.00s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   9708 steps   20.04s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  10819 steps   22.80s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   8449 steps   18.30s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   8986 steps   18.57s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   8298 steps   17.48s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  10840 steps   22.17s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   5570 steps   12.45s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2952 steps    6.04s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3878 steps    8.60s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  10783 steps   22.05s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3054 steps    6.36s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6239 steps   12.98s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3024 steps    7.10s; action: A undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3681 steps    7.55s; action: A undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   5990 steps   12.82s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2174 steps    4.41s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  20000 steps   41.88s; action: ? undefined: 0 converged: 0 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  10004 steps   21.25s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   7958 steps   16.33s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  13566 steps   27.85s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3541 steps    8.75s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  10757 steps   22.00s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4932 steps   10.14s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4455 steps    9.12s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4986 steps   10.24s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   9172 steps   19.83s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6069 steps   12.92s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  12460 steps   25.39s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4259 steps    8.79s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   7929 steps   17.25s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4915 steps   10.70s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   9093 steps   18.63s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3006 steps    6.11s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   9367 steps   19.45s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  13694 steps   29.45s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6658 steps   13.75s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2903 steps    5.96s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   7277 steps   14.85s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   5143 steps   10.62s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4334 steps    9.95s; action: A undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  17827 steps   36.92s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  20000 steps   41.95s; action: ? undefined: 0 converged: 0 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   7133 steps   15.00s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   5260 steps   10.67s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4116 steps    8.58s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6912 steps   14.15s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   8149 steps   17.70s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   8344 steps   17.14s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6352 steps   13.45s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4151 steps    8.55s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   7034 steps   14.67s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4171 steps    8.54s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   7411 steps   15.95s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6003 steps   12.34s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   8944 steps   18.66s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  11295 steps   23.26s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2612 steps    5.38s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   7197 steps   16.19s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3826 steps    7.92s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4349 steps    9.32s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3733 steps    7.62s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6925 steps   14.14s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4898 steps   10.91s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3877 steps    7.97s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  17430 steps   35.91s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6398 steps   13.13s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  10236 steps   22.42s; action: A undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  15912 steps   32.98s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   8077 steps   17.06s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  12408 steps   26.43s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4472 steps    9.36s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1670 steps    3.48s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4715 steps    9.72s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6817 steps   14.25s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4010 steps    8.27s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  17187 steps   36.35s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   8472 steps   17.76s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6707 steps   13.98s; action: A undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   5536 steps   11.51s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  12779 steps   27.16s; action: A undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   8219 steps   17.33s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   7209 steps   14.94s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4049 steps    8.37s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   5823 steps   12.01s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6815 steps   15.08s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  20000 steps   45.57s; action: ? undefined: 0 converged: 0 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3627 steps    7.74s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2874 steps    7.45s; action: A undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  20000 steps   48.80s; action: ? undefined: 0 converged: 0 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  10421 steps   22.55s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   9004 steps   19.01s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4523 steps   10.30s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   7285 steps   15.27s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6891 steps   14.73s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  11365 steps   23.69s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3551 steps    8.57s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2417 steps    5.30s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1894 steps    4.22s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4391 steps    9.52s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2451 steps    5.70s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1271 steps    2.91s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2649 steps    5.82s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:    690 steps    1.53s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2973 steps    7.60s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:    881 steps    1.91s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2355 steps    5.21s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1588 steps    3.51s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:    576 steps    1.31s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1300 steps    2.88s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1387 steps    3.00s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1127 steps    2.47s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2869 steps    6.24s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1839 steps    4.03s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3071 steps    7.70s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1445 steps    3.61s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1604 steps    3.67s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   8828 steps   19.27s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2200 steps    4.91s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1039 steps    2.30s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3666 steps    7.96s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3243 steps    7.06s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2508 steps    6.34s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1661 steps    3.61s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1267 steps    2.74s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1302 steps    3.13s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3768 steps    8.45s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3512 steps    7.60s; action: A undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2851 steps    6.23s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1261 steps    2.74s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2220 steps    5.72s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1312 steps    2.86s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2274 steps    5.00s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1837 steps    4.00s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2351 steps    5.07s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1304 steps    2.84s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2605 steps    5.68s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1262 steps    3.05s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1765 steps    3.96s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2124 steps    5.66s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2363 steps    5.13s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  10764 steps   23.44s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3737 steps    8.16s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2232 steps    4.84s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3381 steps    7.40s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1050 steps    2.29s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3302 steps    8.15s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3757 steps    8.25s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4206 steps    9.25s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1586 steps    3.55s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1746 steps    3.78s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1930 steps    4.20s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1962 steps    4.25s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2413 steps    5.37s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1641 steps    4.85s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3074 steps    6.74s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2997 steps    6.64s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1021 steps    2.24s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1508 steps    3.25s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:    958 steps    2.16s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2048 steps    4.53s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:    828 steps    1.81s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1951 steps    4.25s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1299 steps    3.94s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1030 steps    2.26s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4628 steps   10.17s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2205 steps    4.79s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   7797 steps   17.98s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4065 steps    8.92s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2167 steps    4.76s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   5924 steps   13.94s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:    992 steps    2.17s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:    555 steps    1.26s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1454 steps    3.26s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2221 steps    4.95s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1696 steps    3.72s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3951 steps    9.05s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2123 steps    4.77s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2425 steps    5.32s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1391 steps    4.14s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1071 steps    2.33s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1454 steps    3.22s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2203 steps    4.78s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1041 steps    2.33s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1466 steps    3.22s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2426 steps    5.26s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6860 steps   14.95s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1559 steps    3.40s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3755 steps    9.67s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2046 steps    4.68s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1760 steps    3.87s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2041 steps    4.49s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1404 steps    3.06s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1361 steps    2.96s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1727 steps    3.81s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1960 steps    4.34s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3955 steps   10.37s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2424 steps    5.96s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1883 steps    4.51s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4407 steps   11.11s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2451 steps    6.10s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1271 steps    3.04s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2649 steps    6.38s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:    690 steps    1.67s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2944 steps    7.06s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:    881 steps    3.01s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2355 steps    5.70s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1588 steps    3.81s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:    576 steps    1.37s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1300 steps    3.12s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1387 steps    3.32s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1127 steps    2.74s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2682 steps    6.37s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1839 steps    4.63s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3071 steps    7.56s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1445 steps    4.51s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1604 steps    3.82s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   8828 steps   21.22s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2207 steps    5.25s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1039 steps    2.53s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3666 steps    9.08s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3292 steps    8.27s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2508 steps    7.38s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1661 steps    4.23s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1267 steps    3.06s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1302 steps    3.13s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3768 steps   10.47s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3512 steps    8.66s; action: A undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2704 steps    6.66s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1261 steps    3.13s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2220 steps    6.00s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1312 steps    5.13s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2273 steps    6.61s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1816 steps    4.35s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2351 steps    7.36s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1304 steps    3.17s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2605 steps    6.40s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1262 steps    3.16s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1765 steps    4.31s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2124 steps    5.30s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2363 steps    6.07s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:  15711 steps   40.42s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3737 steps    9.14s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2223 steps    5.32s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3381 steps    8.19s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1050 steps    3.49s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3301 steps    8.10s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3757 steps    9.50s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3962 steps    9.45s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1586 steps    3.81s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1746 steps    4.15s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1911 steps    4.71s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1962 steps    4.82s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2413 steps    6.82s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1641 steps    3.92s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3074 steps    7.45s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2997 steps    8.02s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1021 steps    2.51s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1489 steps    3.60s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:    958 steps    2.30s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2048 steps    6.06s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:    828 steps    2.00s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1970 steps    4.88s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1299 steps    3.20s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1039 steps    2.79s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   5592 steps   13.63s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2205 steps    5.38s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   8156 steps   20.85s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   4074 steps    9.78s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2167 steps    5.31s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   5924 steps   14.51s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:    992 steps    2.45s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:    555 steps    1.33s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1454 steps    3.48s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2218 steps    6.19s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1696 steps    4.15s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3975 steps    9.75s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2123 steps    5.21s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2425 steps    6.01s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1391 steps    3.38s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1071 steps    2.56s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1454 steps    3.49s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2204 steps    6.33s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1041 steps    2.51s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1466 steps    3.52s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2426 steps    6.19s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   6857 steps   19.51s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1559 steps    4.94s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   3755 steps    9.80s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2046 steps    5.20s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1760 steps    4.49s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   2041 steps    5.03s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1389 steps    4.95s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1357 steps    3.43s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1727 steps    4.55s; action: B undefined: 0 converged: 1 polarized: 0 \n",
      " INFO polygraphs> Sim #0001:   1960 steps    4.75s; action: B undefined: 0 converged: 1 polarized: 0 \n"
     ]
    }
   ],
   "source": [
    "groups_to_check = [2,3]\n",
    "prejudiced_amounts_to_check = [1]\n",
    "seeds_to_check = [i for i in range(51100, 51200)]\n",
    "sizes_to_check = [16,64]\n",
    "\n",
    "for size in sizes_to_check:\n",
    "    for group in groups_to_check:\n",
    "        for prejudiced_amount in prejudiced_amounts_to_check:\n",
    "            for seed in seeds_to_check:\n",
    "                params = prejudice_params(size=size, groups=group, prejudiced_certainty=prejudiced_amount, non_prejudiced_certainty=1, seed=seed)\n",
    "                #(size, groups, prejudiced_certainty, non_prejudiced_certainty, seed)\n",
    "                params.simulation.results = f\"data3_control/EI-{size}-{group}-{prejudiced_amount}-{seed}\"\n",
    "                _ = pg.simulate(params, op=EpistemicInjusticeOp)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "test_list = [0,1,2]\n",
    "\n",
    "random.shuffle(test_list)\n",
    "\n",
    "print(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpistemicInjusticeOp(ops.core.PolyGraphOp):\n",
    "    \"\"\"\n",
    "   \n",
    "    Upon receipt, all nodes apply Jeffrey's rule.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, graph, params):\n",
    "        super().__init__(graph, params)\n",
    "        \n",
    "        # Grabbing list of group labels\n",
    "        self.groups = torch.unique(graph.ndata['group']).tolist()\n",
    "        \n",
    "        # Grabbing certainty value for Jeffrey's Rule where testimonial injustice occurs\n",
    "        self.default_certainty = params.trust\n",
    "\n",
    "        # Grabbing certainty values for Jeffrey's Rule where testimonial injustice does not occur\n",
    "        self.prejudice_amount = params.mistrust\n",
    "\n",
    "        #print(\"Total:\",graph.ndata[\"group\"])\n",
    "\n",
    "        #  # Create group masks\n",
    "        # self.group_masks = {}\n",
    "\n",
    "        # for group in self.groups:\n",
    "        #     self.group_masks[group] = (graph.ndata['group'] == group)\n",
    "        # # print((graph.ndata['group']))\n",
    "        # # print(self.group_masks[0])\n",
    "\n",
    "    def messagefn(self):\n",
    "        \"\"\"\n",
    "        Message function\n",
    "        \"\"\"\n",
    "\n",
    "        def function(edges):\n",
    "            return {\n",
    "                \"payoffs\": edges.src[\"payoffs\"],\n",
    "                \"group\": edges.src[\"group\"],\n",
    "            }\n",
    "\n",
    "        return function\n",
    "\n",
    "    def reducefn(self):\n",
    "        \"\"\"\n",
    "        Reduce function\n",
    "        \"\"\"\n",
    "\n",
    "        def function(nodes):\n",
    "            # Log probability of successful trials\n",
    "            logits = nodes.data[\"logits\"]\n",
    "            # Prior, P(H) (aka. belief)\n",
    "            prior = nodes.data[\"beliefs\"]\n",
    "            # Current Node's group\n",
    "            recipient_group = nodes.data[\"group\"]\n",
    "\n",
    "            #print(\"Recipients:\",recipient_group)\n",
    "            ##print(\"Mailbox group:\",nodes.mailbox[\"group\"])\n",
    "            ##print(\"All payoffs:\",nodes.mailbox[\"payoffs\"])\n",
    "\n",
    "            # Duplicate each node's group label across columns for every neighbor\n",
    "            # recipient_group_expanded = recipient_group.unsqueeze(1).expand(-1, nodes.mailbox[\"group\"].shape[1])\n",
    "\n",
    "            #print(\"expanded:\",recipient_group_expanded)\n",
    "            # print(\"Mailbox Groups\")\n",
    "            #print(\"mailbox group:\",nodes.mailbox[\"group\"])\n",
    "            # print(\"mailbox payoffs shape:\",nodes.mailbox[\"payoffs\"].shape)\n",
    "            #print(\"shape of nodes.data[group]\",nodes.data[\"group\"].shape)\n",
    "            \n",
    "            default_certainty = self.default_certainty\n",
    "            prejudice_amount = self.prejudice_amount # Amount of discrediting for instances of testimonial injustice\n",
    "\n",
    "            for group in self.groups:\n",
    "                group_mask = (nodes.mailbox[\"group\"] == group)\n",
    "            \n",
    "                masked_payoffs = nodes.mailbox[\"payoffs\"] * group_mask.unsqueeze(-1).float()\n",
    "                \n",
    "                #print(\"Iterating over group:\",group,)\n",
    "                ##print(\"Masked Payoffs:\",masked_payoffs)\n",
    "\n",
    "                    # TOTAL CERTAINTY TENSOR, PROBABLY NOT NEEDED\n",
    "                    # certainty_bin = (nodes.mailbox[\"group\"] == 0) & (recipient_group_expanded == 1)\n",
    "                    # #print(\"certainty\",certainty_bin)\n",
    "\n",
    "                    # # Define inverse mask\n",
    "                    # certainty_bin_inv = ~certainty_bin\n",
    "                    # #print(\"certainty inverse\",certainty_bin_inv)\n",
    "\n",
    "                    # # Set certainty in case of prejudice\n",
    "                    # prejudiced_certainty = certainty_bin * 0.5 # Amount of discrediting, max: 0, min: 1\n",
    "\n",
    "                    # # Set certainity for all other cases\n",
    "                    # non_prejudiced_certainty = certainty_bin_inv * .9\n",
    "                \n",
    "                # Define nodes belonging to group 0 as prejudiced-against\n",
    "                # (The certainty value for instances of testimonial injustice is applied only if the payoffs are sent by group 0)\n",
    "                if group == 0:\n",
    "\n",
    "                    # Define nodes belonging to group 1 as prejudiced\n",
    "                    prejudiced_nodes_mask = (recipient_group == 1)\n",
    "\n",
    "                    # Define all other nodes as non-prejudiced\n",
    "                    non_prejudiced_nodes_mask = ~prejudiced_nodes_mask\n",
    "\n",
    "                    # print(recipient_group)\n",
    "                    # print(\"Prejudiced nodes:\",prejudiced_nodes_mask)\n",
    "                    # print(non_prejudiced_nodes_mask)\n",
    "\n",
    "                    # Set certainty in case of prejudice\n",
    "                    prejudiced_certainty = prejudiced_nodes_mask * prejudice_amount\n",
    "\n",
    "                    # Set certainity for all other cases\n",
    "                    non_prejudiced_certainty = non_prejudiced_nodes_mask * default_certainty\n",
    "\n",
    "                    # Combine certainty tensors\n",
    "                    certainty = prejudiced_certainty + non_prejudiced_certainty\n",
    "\n",
    "                    #print(\"Combined certainty:\",certainty)\n",
    "\n",
    "                    # Sum values for all neighbors belonging to current sender group\n",
    "                    sender_group_values = torch.sum(masked_payoffs[:, :, 0], dim=1)\n",
    "                    ##print(\"Masked values sum:\",sender_group_values)\n",
    "\n",
    "                    # Sum trials for all neighbors belonging to current sender group\n",
    "                    sender_group_trials = torch.sum(masked_payoffs[:, :, 1], dim=1)\n",
    "                    #print(\"Masked trials sum:\",sender_group_trials)\n",
    "\n",
    "                    # Evidence, E\n",
    "                    evidence = math.Evidence(logits, sender_group_values, sender_group_trials)\n",
    "                    # print(\"Evidence:\",evidence)\n",
    "\n",
    "                    # Apply Jeffrey's Rule to all nodes\n",
    "                    posterior = math.jeffrey(prior, evidence, certainty)\n",
    "\n",
    "                    # Consider next sender group\n",
    "                    prior = posterior\n",
    "\n",
    "\n",
    "                else:\n",
    "\n",
    "                    # Create a tensor with a 1 for each node in the network \n",
    "                    recipient_ones = torch.ones_like(recipient_group)\n",
    "                    # Multiply 1's by default certainty\n",
    "                    certainty = recipient_ones * default_certainty\n",
    "                    #print(\"Combined certainty:\",certainty)\n",
    "                    \n",
    "                    # Sum values for all neighbors belonging to current sender group\n",
    "                    sender_group_values = torch.sum(masked_payoffs[:, :, 0], dim=1)\n",
    "                    #print(\"masked values sum:\",sender_group_values)\n",
    "\n",
    "                    # Sum trials for all neighbors belonging to current sender group\n",
    "                    sender_group_trials = torch.sum(masked_payoffs[:, :, 1], dim=1)\n",
    "                    # print(\"masked trials sum:\",sender_group_trials)\n",
    "\n",
    "                    # Evidence, E\n",
    "                    evidence = math.Evidence(logits, sender_group_values, sender_group_trials)\n",
    "                    # print(\"Evidence:\",evidence)\n",
    "\n",
    "                    # Apply Jeffrey's Rule to all nodes\n",
    "                    posterior = math.jeffrey(prior, evidence, certainty)\n",
    "                    \n",
    "                    # Consider next sender group\n",
    "                    prior = posterior\n",
    "\n",
    "            # Return posterior beliefs\n",
    "            return {\"beliefs\": posterior}\n",
    "\n",
    "        return function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpistemicInjusticeOp_Shuffled(ops.core.PolyGraphOp):\n",
    "    \"\"\"\n",
    "   \n",
    "    Upon receipt, all nodes apply Jeffrey's rule.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, graph, params):\n",
    "        super().__init__(graph, params)\n",
    "        \n",
    "        # Grabbing list of group labels\n",
    "        self.groups = torch.unique(graph.ndata['group']).tolist()\n",
    "        \n",
    "        # Grabbing certainty value for Jeffrey's Rule where testimonial injustice occurs\n",
    "        self.default_certainty = params.trust\n",
    "\n",
    "        # Grabbing certainty values for Jeffrey's Rule where testimonial injustice does not occur\n",
    "        self.prejudice_amount = params.mistrust\n",
    "\n",
    "        #print(\"Total:\",graph.ndata[\"group\"])\n",
    "\n",
    "        #  # Create group masks\n",
    "        # self.group_masks = {}\n",
    "\n",
    "        # for group in self.groups:\n",
    "        #     self.group_masks[group] = (graph.ndata['group'] == group)\n",
    "        # # print((graph.ndata['group']))\n",
    "        # # print(self.group_masks[0])\n",
    "\n",
    "    def messagefn(self):\n",
    "        \"\"\"\n",
    "        Message function\n",
    "        \"\"\"\n",
    "\n",
    "        def function(edges):\n",
    "            return {\n",
    "                \"payoffs\": edges.src[\"payoffs\"],\n",
    "                \"group\": edges.src[\"group\"],\n",
    "            }\n",
    "\n",
    "        return function\n",
    "\n",
    "    def reducefn(self):\n",
    "        \"\"\"\n",
    "        Reduce function\n",
    "        \"\"\"\n",
    "\n",
    "        def function(nodes):\n",
    "            # Log probability of successful trials\n",
    "            logits = nodes.data[\"logits\"]\n",
    "            # Prior, P(H) (aka. belief)\n",
    "            prior = nodes.data[\"beliefs\"]\n",
    "            # Current Node's group\n",
    "            recipient_group = nodes.data[\"group\"]\n",
    "\n",
    "            #print(\"Recipients:\",recipient_group)\n",
    "            ##print(\"Mailbox group:\",nodes.mailbox[\"group\"])\n",
    "            ##print(\"All payoffs:\",nodes.mailbox[\"payoffs\"])\n",
    "\n",
    "            # Duplicate each node's group label across columns for every neighbor\n",
    "            # recipient_group_expanded = recipient_group.unsqueeze(1).expand(-1, nodes.mailbox[\"group\"].shape[1])\n",
    "\n",
    "            #print(\"expanded:\",recipient_group_expanded)\n",
    "            # print(\"Mailbox Groups\")\n",
    "            #print(\"mailbox group:\",nodes.mailbox[\"group\"])\n",
    "            # print(\"mailbox payoffs shape:\",nodes.mailbox[\"payoffs\"].shape)\n",
    "            #print(\"shape of nodes.data[group]\",nodes.data[\"group\"].shape)\n",
    "            \n",
    "            default_certainty = self.default_certainty\n",
    "            prejudice_amount = self.prejudice_amount # Amount of discrediting for instances of testimonial injustice\n",
    "\n",
    "            #Shuffle group list in place\n",
    "            random.shuffle(self.groups)\n",
    "            #print(self.groups)\n",
    "\n",
    "            for group in self.groups:\n",
    "                group_mask = (nodes.mailbox[\"group\"] == group)\n",
    "            \n",
    "                masked_payoffs = nodes.mailbox[\"payoffs\"] * group_mask.unsqueeze(-1).float()\n",
    "                \n",
    "                #print(\"Iterating over group:\",group,)\n",
    "                ##print(\"Masked Payoffs:\",masked_payoffs)\n",
    "\n",
    "                    # TOTAL CERTAINTY TENSOR, PROBABLY NOT NEEDED\n",
    "                    # certainty_bin = (nodes.mailbox[\"group\"] == 0) & (recipient_group_expanded == 1)\n",
    "                    # #print(\"certainty\",certainty_bin)\n",
    "\n",
    "                    # # Define inverse mask\n",
    "                    # certainty_bin_inv = ~certainty_bin\n",
    "                    # #print(\"certainty inverse\",certainty_bin_inv)\n",
    "\n",
    "                    # # Set certainty in case of prejudice\n",
    "                    # prejudiced_certainty = certainty_bin * 0.5 # Amount of discrediting, max: 0, min: 1\n",
    "\n",
    "                    # # Set certainity for all other cases\n",
    "                    # non_prejudiced_certainty = certainty_bin_inv * .9\n",
    "                \n",
    "                # Define nodes belonging to group 0 as prejudiced-against\n",
    "                # (The certainty value for instances of testimonial injustice is applied only if the payoffs are sent by group 0)\n",
    "                if group == 0:\n",
    "\n",
    "                    # Define nodes belonging to group 1 as prejudiced\n",
    "                    prejudiced_nodes_mask = (recipient_group == 1)\n",
    "\n",
    "                    # Define all other nodes as non-prejudiced\n",
    "                    non_prejudiced_nodes_mask = ~prejudiced_nodes_mask\n",
    "\n",
    "                    # print(recipient_group)\n",
    "                    # print(\"Prejudiced nodes:\",prejudiced_nodes_mask)\n",
    "                    # print(non_prejudiced_nodes_mask)\n",
    "\n",
    "                    # Set certainty in case of prejudice\n",
    "                    prejudiced_certainty = prejudiced_nodes_mask * prejudice_amount\n",
    "\n",
    "                    # Set certainity for all other cases\n",
    "                    non_prejudiced_certainty = non_prejudiced_nodes_mask * default_certainty\n",
    "\n",
    "                    # Combine certainty tensors\n",
    "                    certainty = prejudiced_certainty + non_prejudiced_certainty\n",
    "\n",
    "                    #print(\"Combined certainty:\",certainty)\n",
    "\n",
    "                    # Sum values for all neighbors belonging to current sender group\n",
    "                    sender_group_values = torch.sum(masked_payoffs[:, :, 0], dim=1)\n",
    "                    ##print(\"Masked values sum:\",sender_group_values)\n",
    "\n",
    "                    # Sum trials for all neighbors belonging to current sender group\n",
    "                    sender_group_trials = torch.sum(masked_payoffs[:, :, 1], dim=1)\n",
    "                    #print(\"Masked trials sum:\",sender_group_trials)\n",
    "\n",
    "                    # Evidence, E\n",
    "                    evidence = math.Evidence(logits, sender_group_values, sender_group_trials)\n",
    "                    # print(\"Evidence:\",evidence)\n",
    "\n",
    "                    # Apply Jeffrey's Rule to all nodes\n",
    "                    posterior = math.jeffrey(prior, evidence, certainty)\n",
    "\n",
    "                    # Consider next sender group\n",
    "                    prior = posterior\n",
    "\n",
    "\n",
    "                else:\n",
    "\n",
    "                    # Create a tensor with a 1 for each node in the network \n",
    "                    recipient_ones = torch.ones_like(recipient_group)\n",
    "                    # Multiply 1's by default certainty\n",
    "                    certainty = recipient_ones * default_certainty\n",
    "                    #print(\"Combined certainty:\",certainty)\n",
    "                    \n",
    "                    # Sum values for all neighbors belonging to current sender group\n",
    "                    sender_group_values = torch.sum(masked_payoffs[:, :, 0], dim=1)\n",
    "                    #print(\"masked values sum:\",sender_group_values)\n",
    "\n",
    "                    # Sum trials for all neighbors belonging to current sender group\n",
    "                    sender_group_trials = torch.sum(masked_payoffs[:, :, 1], dim=1)\n",
    "                    # print(\"masked trials sum:\",sender_group_trials)\n",
    "\n",
    "                    # Evidence, E\n",
    "                    evidence = math.Evidence(logits, sender_group_values, sender_group_trials)\n",
    "                    # print(\"Evidence:\",evidence)\n",
    "\n",
    "                    # Apply Jeffrey's Rule to all nodes\n",
    "                    posterior = math.jeffrey(prior, evidence, certainty)\n",
    "                    \n",
    "                    # Consider next sender group\n",
    "                    prior = posterior\n",
    "\n",
    "            # Return posterior beliefs\n",
    "            return {\"beliefs\": posterior}\n",
    "\n",
    "        return function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a complete DGL graph with random groups\n",
    "def create_complete_graph_with_groups(size):\n",
    "    # 1. Create a complete graph using NetworkX\n",
    "    nx_graph = nx.complete_graph(size)\n",
    "    \n",
    "    # 2. Convert NetworkX graph to DGL graph\n",
    "    dgl_graph = dgl.from_networkx(nx_graph)\n",
    "    \n",
    "    groups = 3\n",
    "\n",
    "    # Shuffle the nodes\n",
    "    nodes = list(range(size))\n",
    " \n",
    "\n",
    "    # Calculate nodes per group and the remainder\n",
    "    nodes_per_group = size // groups\n",
    "    remainder = size % groups\n",
    "    \n",
    "    group_tensor = torch.zeros(size, dtype=torch.int64)\n",
    "    node_idx = 0\n",
    "    \n",
    "    for group_idx in range(groups):\n",
    "        group_size = nodes_per_group + (1 if group_idx < remainder else 0)\n",
    "        group_nodes = nodes[node_idx:node_idx + group_size]\n",
    "        group_tensor[group_nodes] = group_idx\n",
    "        node_idx += group_size\n",
    "\n",
    "    # Add the group assignments to the graph\n",
    "    dgl_graph.ndata['group'] = group_tensor\n",
    "\n",
    "    # Assign arbitrary values to each node\n",
    "    arbitrary_values = torch.rand(size)  # Replace with any arbitrary values\n",
    "    dgl_graph.ndata['value'] = arbitrary_values\n",
    "\n",
    "    return dgl_graph\n",
    "\n",
    "# Example usage\n",
    "size = 9  # Number of nodes in the graph\n",
    "dgl_graph = create_complete_graph_with_groups(size)\n",
    "\n",
    "# Check node features\n",
    "print(dgl_graph.ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamically create masks for each group\n",
    "group_masks = {}\n",
    "groups_test = 3\n",
    "for group in range(groups_test):\n",
    "    group_masks[group] = (dgl_graph.ndata['group'] == group)\n",
    "\n",
    "# Check masks\n",
    "for group in group_masks:\n",
    "    print(f\"Mask for group {group}: {group_masks[group]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract masks for nodes by group\n",
    "group_0_mask = (dgl_graph.ndata['group'] == 0)\n",
    "group_1_mask = (dgl_graph.ndata['group'] == 1)\n",
    "\n",
    "# Check \n",
    "print(group_0_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract values for each group\n",
    "values_group_0 = dgl_graph.ndata['value'][group_0_mask]\n",
    "values_group_1 = dgl_graph.ndata['value'][group_1_mask]\n",
    "\n",
    "print(\"Values for group 0 nodes:\", values_group_0)\n",
    "print(\"Values for group 1 nodes:\", values_group_1)\n",
    "\n",
    "# Perform some arbitrary computation, for example, summing the values in each group\n",
    "sum_values_group_0 = values_group_0.sum().item()\n",
    "sum_values_group_1 = values_group_1.sum().item()\n",
    "\n",
    "print(f\"Sum of values for group 0: {sum_values_group_0}\")\n",
    "print(f\"Sum of values for group 1: {sum_values_group_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_grouped_(size, groups, selfloop=True):\n",
    "    \"\"\"\n",
    "    Returns a grouped, undirected fully-connected graph.\n",
    "    \"\"\"\n",
    "    # Check network size\n",
    "    assert size > 1\n",
    "    # Check group size\n",
    "    assert groups > 0 and groups <= size\n",
    "    # Get graph from networkx\n",
    "    graph = dgl.from_networkx(nx.complete_graph(size))\n",
    "\n",
    "    # Shuffle the nodes\n",
    "    nodes = list(range(size))\n",
    "    random.shuffle(nodes)\n",
    "    \n",
    "    # Calculate nodes per group and the remainder\n",
    "    nodes_per_group = size // groups\n",
    "    remainder = size % groups\n",
    "    \n",
    "    group_tensor = torch.zeros(size, dtype=torch.int64)\n",
    "    node_idx = 0\n",
    "    \n",
    "    for group_idx in range(groups):\n",
    "        group_size = nodes_per_group + (1 if group_idx < remainder else 0)\n",
    "        group_nodes = nodes[node_idx:node_idx + group_size]\n",
    "        group_tensor[group_nodes] = group_idx\n",
    "        node_idx += group_size\n",
    "    \n",
    "    # Add group information as a node feature\n",
    "    graph.ndata['group'] = group_tensor\n",
    "\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JTest(ops.core.PolyGraphOp):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, graph, params):\n",
    "        super().__init__(graph, params)\n",
    "\n",
    "        # Multiplier that captures how quickly agents become uncertain about\n",
    "        # the evidence of their peers as their beliefs diverge.\n",
    "        self.mistrust = params.mistrust\n",
    "\n",
    "        # Whether to discount evidence with unti-updating or not\n",
    "        self.antiupdating = params.antiupdating\n",
    "\n",
    "    def filterfn(self):\n",
    "        \"\"\"\n",
    "        # Filters out edges whose source has no evidence to report\n",
    "        \"\"\"\n",
    "\n",
    "        def function(edges):\n",
    "            return torch.gt(edges.src[\"payoffs\"][:, 1], 0.0)\n",
    "\n",
    "        return function\n",
    "\n",
    "    def messagefn(self):\n",
    "        \"\"\"\n",
    "        Message function\n",
    "        \"\"\"\n",
    "\n",
    "        def function(edges):\n",
    "            return {\"payoffs\": edges.src[\"payoffs\"], \"beliefs\": edges.src[\"beliefs\"]}\n",
    "\n",
    "        return function\n",
    "\n",
    "    def _distancefn(self, delta):\n",
    "        \"\"\"\n",
    "        Distance function\n",
    "        \"\"\"\n",
    "        return delta * self.mistrust\n",
    "\n",
    "    def reducefn(self):\n",
    "        \"\"\"\n",
    "        Reduce function\n",
    "        \"\"\"\n",
    "\n",
    "        def function(nodes):\n",
    "            # Log probability of successful trials\n",
    "            logits = nodes.data[\"logits\"]\n",
    "            # Prior, P(H) (aka. belief)\n",
    "            prior = nodes.data[\"beliefs\"]\n",
    "\n",
    "            attrs = vars(nodes)\n",
    "            #print(', '.join(\"%s: %s\" % item for item in attrs.items()))\n",
    "            # Number of nodes and number of neighbours per node (incoming messages)\n",
    "\n",
    "            # print(nodes.mailbox[\"payoffs\"])\n",
    "            # print(\"break\")\n",
    "            # print(nodes.mailbox[\"payoffs\"][:, :, 1])\n",
    "            _, neighbours = nodes.mailbox[\"beliefs\"].shape\n",
    "        \n",
    "            for i in range(neighbours):\n",
    "                # A node receives evidence E from its i-th neighbour, say Jill,\n",
    "                # denoting the number of successful trials and the total number\n",
    "                # of trials she observed\n",
    "                mailboxf = nodes.mailbox[\"payoffs\"]\n",
    "                values = nodes.mailbox[\"payoffs\"][:, i, 0]\n",
    "                trials = nodes.mailbox[\"payoffs\"][:, i, 1]\n",
    "                print(f\"The neighbor is: {i} The values are: {values} The mailbox is: {mailboxf}\")\n",
    "\n",
    "                # Evidence, E\n",
    "                evidence = math.Evidence(logits, values, trials)\n",
    "\n",
    "                # The difference in belief between an agent\n",
    "                # and its i-th neighbour\n",
    "                delta = torch.abs(prior - nodes.mailbox[\"beliefs\"][:, i])\n",
    "            \n",
    "                # Compute belief that the evidence E is real, P(E)(d)\n",
    "                if self.antiupdating:\n",
    "                    certainty = torch.max(\n",
    "                        1.0\n",
    "                        - self._distancefn(delta)\n",
    "                        * (1.0 - math.marginal(prior, evidence)),\n",
    "                        torch.zeros((len(nodes),)),\n",
    "                    )\n",
    "                else:\n",
    "                    # Consider an agent u and one of its neighbours, v. As\n",
    "                    # beliefs between u and v diverge (delta towards 1),\n",
    "                    # agent u simply ignores the evidence of agent v.\n",
    "                    #\n",
    "                    # If delta becomes 1, uncertainty ~ marginal. In other\n",
    "                    # words, agent u's belief remains unchanged in light of\n",
    "                    # agent v's evidence.\n",
    "                    #\n",
    "                    # The multiplier simply determines how far apart beliefs\n",
    "                    # have to become before agent u begins to ignore the\n",
    "                    # evidence of its neighbour, v (since delta never becomes 1)\n",
    "                    certainty = 1.0 - torch.min(\n",
    "                        torch.ones((len(nodes),)), self._distancefn(delta)\n",
    "                    ) * (1.0 - math.marginal(prior, evidence))\n",
    "\n",
    "                # Compute posterior belief, in light of soft uncertainty\n",
    "                posterior = math.jeffrey(prior, evidence, certainty)\n",
    "\n",
    "                # Consider next neighbour\n",
    "                prior = posterior\n",
    "\n",
    "            # Return posterior beliefs for each neighbour\n",
    "            return {\"beliefs\": posterior}\n",
    "\n",
    "        return function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polygraphs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
