{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import polygraphs as pg\n",
    "import torch\n",
    "\n",
    "\n",
    "def generator(epsilon, trials, size):\n",
    "    # Action B yields Bernoulli payoff of 1 (success)\n",
    "    # with probability p (= 0.5 + e)\n",
    "    probs = pg.init.halfs(size) + epsilon\n",
    "    \n",
    "    # Number of Bernoulli trials\n",
    "    count = pg.init.zeros(size) + trials\n",
    "\n",
    "    # Each node gets a private signal that provides information\n",
    "    # about whether action B is indeed a good action\n",
    "    sampler = torch.distributions.binomial.Binomial(total_count=count, probs=probs)\n",
    "    return sampler\n",
    "\n",
    "def jeffrey(prior, certainty, evidence):\n",
    "    \"\"\"\n",
    "    Computes posterior based on Jeffrey's rule.\n",
    "    \"\"\"\n",
    "    Z = pg.init.zeros((1000, 1000))\n",
    "    for i in range(1000):\n",
    "        Z[i] = pg.ops.math.jeffrey(prior, evidence, certainty[i])\n",
    "    return Z\n",
    "\n",
    "\n",
    "def jeffrey_inc(prior, certainty, evidence):\n",
    "    \"\"\"\n",
    "    Computes posterior based on Jeffrey's rule.\n",
    "    \"\"\"\n",
    "    Z = pg.init.zeros((1000, 1000))\n",
    "    shards = 10\n",
    "    sharded_evidence = pg.ops.math.Evidence(evidence.logits, evidence.values / shards, evidence.trials / 10)\n",
    "    for i in range(1000):\n",
    "        Z[i] = pg.ops.math.jeffrey(prior, sharded_evidence, certainty[i])\n",
    "        for _ in range(shards - 1):\n",
    "            Z[i] = pg.ops.math.jeffrey(Z[i], sharded_evidence, certainty[i])\n",
    "    return Z\n",
    "\n",
    "\n",
    "# Probability of success is 0.5 + epsilon\n",
    "epsilon1 = 0.001\n",
    "\n",
    "# Number of trials per node\n",
    "trials = 100\n",
    "\n",
    "size = 1000\n",
    "\n",
    "prior = torch.tensor(np.linspace(0.0, 1.0, 1000))\n",
    "# print(\"Prior is\", prior)\n",
    "\n",
    "certainty = np.linspace(0.0, 1.0, 1000)\n",
    "\n",
    "g1 = generator(epsilon1, trials, size)\n",
    "\n",
    "e1 = pg.ops.math.Evidence(g1.logits, g1.mean, g1.total_count)\n",
    "\n",
    "posterior1 = jeffrey_inc(prior, certainty, e1)\n",
    "\n",
    "print(posterior1.shape)\n",
    "print(torch.max(posterior1))\n",
    "\n",
    "# plt.clim(0, 1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12,10))\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = plt.axes(projection='3d')\n",
    "\n",
    "# ax.set_aspect('equal')\n",
    "\n",
    "ax.set(xlabel=\"Prior\")\n",
    "ax.set(ylabel=\"Certainty\")\n",
    "\n",
    "ax.set_title(f\"$e$ = {epsilon1}, {trials} trials, 10 shards\")\n",
    "\n",
    "cf = ax.contourf(prior, certainty, posterior1, levels=10, cmap=plt.cm.bone)\n",
    "\n",
    "cf2 = ax.contour(cf, colors='r')\n",
    "\n",
    "ax.clabel(cf2, inline=True, fontsize=10)\n",
    "\n",
    "cbar = fig.colorbar(cf, ax=ax)\n",
    "\n",
    "cbar.ax.set_ylabel('Posterior')\n",
    "# Add the contour line levels to the colorbar\n",
    "cbar.add_lines(cf2)\n",
    "\n",
    "# ax.plot(prior, posterior1, color=\"red\")\n",
    "# ax.plot(prior, posterior2, color=\"blue\")\n",
    "# ax.plot(prior, posterior3, color=\"green\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import polygraphs as pg\n",
    "import torch\n",
    "\n",
    "\n",
    "def generator(epsilon, trials, size):\n",
    "    # Action B yields Bernoulli payoff of 1 (success)\n",
    "    # with probability p (= 0.5 + e)\n",
    "    probs = pg.init.halfs(size) + epsilon\n",
    "    \n",
    "    # Number of Bernoulli trials\n",
    "    count = pg.init.zeros(size) + trials\n",
    "\n",
    "    # Each node gets a private signal that provides information\n",
    "    # about whether action B is indeed a good action\n",
    "    sampler = torch.distributions.binomial.Binomial(total_count=count, probs=probs)\n",
    "    return sampler\n",
    "\n",
    "\n",
    "def jeffrey(prior, certainty, evidence, size):\n",
    "    \"\"\"\n",
    "    Computes posterior based on Jeffrey's rule.\n",
    "    \"\"\"\n",
    "    Z = pg.init.zeros((size, size))\n",
    "    for i in range(size):\n",
    "        Z[i] = pg.ops.math.jeffrey(prior, evidence, certainty[i])\n",
    "    return Z\n",
    "\n",
    "\n",
    "def jeffrey2(prior, certainty, evidence, size, shards=None):\n",
    "    \"\"\"\n",
    "    Computes posterior based on Jeffrey's rule.\n",
    "    \"\"\"\n",
    "    Z = pg.ops.math.jeffrey(prior, evidence, certainty)\n",
    "    return Z\n",
    "\n",
    "\n",
    "def jeffreyinc(prior, certainty, evidence, size, shards=10):\n",
    "    \"\"\"\n",
    "    Computes posterior based on Jeffrey's rule incremental.\n",
    "    \"\"\"\n",
    "    Z = pg.init.zeros((size, size))\n",
    "    # Shard the evidence\n",
    "    e = pg.ops.math.Evidence(evidence.logits, evidence.values / shards, evidence.trials / shards)\n",
    "    for i in range(size):\n",
    "        Z[i] = pg.ops.math.jeffrey(prior, e, certainty[i])\n",
    "        for _ in range(shards - 1):\n",
    "            Z[i] = pg.ops.math.jeffrey(Z[i], e, certainty[i])\n",
    "    return Z\n",
    "\n",
    "\n",
    "def jeffreyinc2(prior, certainty, evidence, size, shards=10):\n",
    "    \"\"\"\n",
    "    Computes posterior based on Jeffrey's rule incremental.\n",
    "    \"\"\"\n",
    "    # Shard the evidence\n",
    "    e = pg.ops.math.Evidence(evidence.logits, evidence.values / shards, evidence.trials / shards)\n",
    "    Z = pg.ops.math.jeffrey(prior, e, certainty)\n",
    "    for _ in range(shards - 1):\n",
    "        Z = pg.ops.math.jeffrey(Z, e, certainty)\n",
    "    return Z\n",
    "\n",
    "\n",
    "# Probability of success is 0.5 + epsilon\n",
    "epsilon1 = 0.1\n",
    "\n",
    "# Number of trials per node\n",
    "trials = 100\n",
    "\n",
    "size = 1000\n",
    "\n",
    "prior = torch.tensor(np.linspace(0.0, 1.0, size))\n",
    "# print(\"Prior is\", prior)\n",
    "\n",
    "certainty = np.linspace(0.0, 1.0, size)\n",
    "\n",
    "g1 = generator(epsilon1, trials, size)\n",
    "\n",
    "e1 = pg.ops.math.Evidence(g1.logits, g1.mean, g1.total_count)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,10))\n",
    "\n",
    "ax.set(xlabel=\"Prior\")\n",
    "ax.set(ylabel=\"Posterior\")\n",
    "# ax.set(xlim=[0, 1])\n",
    "# ax.set(ylim=[0, 1])\n",
    "\n",
    "ax.plot(prior, pg.ops.math.bayes(prior, e1), linewidth=5)\n",
    "\n",
    "# Let's compute Jeffrey's rule\n",
    "\n",
    "C = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for k in C:\n",
    "    post1 = jeffreyinc2(prior, k, e1, size, shards=10)\n",
    "    ax.plot(prior, post1, \"--\", linewidth=1, label=f\"{C}\")\n",
    "    post2 = jeffrey2(prior, k, e1, size, shards=10)\n",
    "    ax.plot(prior, post2, linewidth=1, label=f\"{C}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('polygraphs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85bf0e9c58eee383cf410aa2386a3c5163b13680be7e32b9f97c0a8ccc9ea0ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
