{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polygraphs as pg\n",
    "\n",
    "from polygraphs import graphs\n",
    "from polygraphs import hyperparameters as hparams\n",
    "from polygraphs import visualisations as viz\n",
    "from polygraphs import ops\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PolyGraph configuration\n",
    "params = hparams.PolyGraphHyperParameters()\n",
    "\n",
    "# Initial beliefs are random uniform between 0 and 1\n",
    "params.init.kind = 'uniform'\n",
    "# Chance that action B is better than action A\n",
    "params.epsilon = 0.01\n",
    "\n",
    "params.network.kind = 'cycle'\n",
    "params.network.size = 8\n",
    "\n",
    "# Watts Strogatz Parameters\n",
    "params.network.wattsstrogatz.knn = 4\n",
    "params.network.wattsstrogatz.probability = 0.5\n",
    "\n",
    "# Barabasi-Albert Parameters\n",
    "params.network.barabasialbert.attachments = 4\n",
    "\n",
    "# Enable logging; print progress every 100 steps\n",
    "params.logging.enabled = True\n",
    "params.logging.interval = 100\n",
    "\n",
    "# Take snapshots (incl. messages)\n",
    "params.snapshots.enabled = True\n",
    "params.snapshots.interval = 1\n",
    "params.snapshots.messages = True\n",
    "\n",
    "params.simulation.steps = 0\n",
    "params.simulation.repeats = 10\n",
    "\n",
    "# Store results in directory\n",
    "params.simulation.results = \"data/cycle\"\n",
    "\n",
    "# Set seed\n",
    "#params.seed = 123456789\n",
    "\n",
    "pg.random(params.seed)\n",
    "_ = pg.simulate(params, op=ops.BalaGoyalOp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bye.\n"
     ]
    }
   ],
   "source": [
    "from genericpath import exists\n",
    "import os\n",
    "from posixpath import splitext\n",
    "import h5py\n",
    "import json\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import dgl\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def __export_nodes(graph, sim):\n",
    "    \"\"\"\n",
    "    Export nodes\n",
    "    \"\"\"\n",
    "    filename = f\"{sim}-nodes.json\"\n",
    "\n",
    "    data = []\n",
    "    for nid in graph.nodes():\n",
    "        belief = graph.ndata[\"beliefs\"][nid].item()\n",
    "        data.append({\"id\": nid.item(), \"belief\": belief})\n",
    "\n",
    "    with open(filename, \"w\") as fstream:\n",
    "        json.dump(data, fstream, indent=4)\n",
    "    return\n",
    "\n",
    "\n",
    "def __export_links(graph, sim):\n",
    "    \"\"\"\n",
    "    Export links\n",
    "    \"\"\"\n",
    "    filename = f\"{sim}-links.json\"\n",
    "\n",
    "    data = []\n",
    "    src, dst = graph.edges()\n",
    "    for s, t in zip(src, dst):\n",
    "        data.append({\"source\": s.item(), \"target\": t.item()})\n",
    "\n",
    "    with open(filename, \"w\") as fstream:\n",
    "        json.dump(data, fstream, indent=4)\n",
    "    return\n",
    "\n",
    "\n",
    "def __export_messages(graph, iid):\n",
    "    \"\"\"\n",
    "    Export messages from a given iteration (`iid`).\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for u in graph.nodes():\n",
    "        payoff = graph.ndata[\"payoffs\"][u].item()\n",
    "        sample = graph.ndata[\"samples\"][u].item()\n",
    "\n",
    "        # Ingore \"empty\" messages\n",
    "        if sample < 1:\n",
    "            continue\n",
    "\n",
    "        # Iterate over node's neighbours\n",
    "        neighbours = graph.out_edges(u, form=\"uv\")[1]\n",
    "        for v in neighbours:\n",
    "            data.append(\n",
    "                {\n",
    "                    \"iid\": iid,\n",
    "                    \"source\": u.item(),\n",
    "                    \"target\": v.item(),\n",
    "                    \"payoff\": payoff,\n",
    "                    \"sample\": sample,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Return messages from given iteration\n",
    "    return data\n",
    "\n",
    "\n",
    "def __export_beliefs(graph, iid):\n",
    "    \"\"\"\n",
    "    Export beliefs from a given iteration (`iid`).\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for nid in graph.nodes():\n",
    "        belief = graph.ndata[\"beliefs\"][nid].item()\n",
    "        data.append({\"iid\": iid, \"id\": nid.item(), \"belief\": belief})\n",
    "    return data\n",
    "\n",
    "\n",
    "def __export_iterations(graph, snapshots, sim):\n",
    "    \"\"\"\n",
    "    Export iterations\n",
    "    \"\"\"\n",
    "    # Output file\n",
    "    filename = f\"{sim}-iterations.json\"\n",
    "\n",
    "    _keys = [int(key) for key in snapshots[\"beliefs\"].keys()]\n",
    "    _keys = sorted(_keys)\n",
    "\n",
    "    data = []\n",
    "    for key in _keys:\n",
    "        # Populate graph node attributes\n",
    "        graph.ndata[\"beliefs\"] = torch.tensor(snapshots[\"beliefs\"][str(key)][:])\n",
    "        graph.ndata[\"payoffs\"] = torch.tensor(snapshots[\"payoffs\"][str(key)][:].T[0])\n",
    "        graph.ndata[\"samples\"] = torch.tensor(snapshots[\"payoffs\"][str(key)][:].T[1])\n",
    "\n",
    "        # Export messages\n",
    "        data += __export_messages(graph, key)\n",
    "\n",
    "        # Export new node beliefs\n",
    "        data += __export_beliefs(graph, key)\n",
    "\n",
    "    with open(filename, \"w\") as fstream:\n",
    "        json.dump(data, fstream, indent=4)\n",
    "\n",
    "\n",
    "def __export_groupbeliefs(graph, snapshots, sim):\n",
    "    def majority(beliefs, threshold=0.5, weights=None):\n",
    "        \"\"\"\n",
    "        Returns percentage of nodes that believe B is better.\n",
    "        \"\"\"\n",
    "        if weights is None:\n",
    "            weights = torch.ones(beliefs.shape)\n",
    "\n",
    "        zeros = torch.zeros(beliefs.shape, dtype=weights.dtype)\n",
    "\n",
    "        # Count (normalized) votes\n",
    "        votes = torch.where(beliefs > threshold, weights, zeros)\n",
    "        result = votes.sum() / weights.sum()\n",
    "        return result.item()\n",
    "\n",
    "    # Output file\n",
    "    filename = f\"{sim}-groupbeliefs.json\"\n",
    "\n",
    "    _keys = [int(key) for key in snapshots[\"beliefs\"].keys()]\n",
    "    _keys = sorted(_keys)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for key in _keys:\n",
    "        beliefs = torch.tensor(snapshots[\"beliefs\"][str(key)][:])\n",
    "        group_beliefs = {\"iid\": key}\n",
    "\n",
    "        # Is there a simple majority (> 0.5) of NODES whose credence exceeds the threshold (>0.99)?\n",
    "        group_beliefs[\"belief_unweighted\"] = majority(\n",
    "            beliefs=beliefs, threshold=0.99, weights=None\n",
    "        )\n",
    "\n",
    "        group_beliefs[\"belief_weighted\"] = majority(\n",
    "            beliefs=beliefs, threshold=0.99, weights=graph.in_degrees()\n",
    "        )\n",
    "\n",
    "        group_beliefs[\"credence_unweighted\"] = str(np.average(a=beliefs))\n",
    "        group_beliefs[\"credence_weighted\"] = str(\n",
    "            np.average(a=beliefs, weights=graph.in_degrees())\n",
    "        )\n",
    "\n",
    "        data.append(group_beliefs)\n",
    "\n",
    "    with open(filename, \"w\") as fstream:\n",
    "        json.dump(data, fstream, indent=4)\n",
    "\n",
    "\n",
    "def toJSON(sim):\n",
    "    \"\"\"\n",
    "    Post-process graph snapshots and export them into JSON format\n",
    "    \"\"\"\n",
    "    # Load DGL graph\n",
    "    graphs, _ = dgl.load_graphs(f\"{sim}.bin\")\n",
    "    graph = graphs[0]\n",
    "\n",
    "    # Remove self-loops\n",
    "    graph = dgl.remove_self_loop(graph)\n",
    "\n",
    "    # Export nodes\n",
    "    __export_nodes(graph, sim)\n",
    "\n",
    "    # Export links\n",
    "    __export_links(graph, sim)\n",
    "\n",
    "    # Read snapshots\n",
    "    snapshots = h5py.File(f\"{sim}.hd5\", \"r\")\n",
    "\n",
    "    # Export iterations\n",
    "    __export_iterations(graph, snapshots, sim)\n",
    "\n",
    "    # Export group beliefs\n",
    "    __export_groupbeliefs(graph, snapshots, sim)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def export(directory, sims):\n",
    "    # Ensure that the directory exists\n",
    "    assert os.path.isdir(directory)\n",
    "    # If sims is None, find number of simulations\n",
    "    if sims is None:\n",
    "        # List all binary graph files\n",
    "        sims = glob.glob(os.path.join(directory, \"*.bin\"))\n",
    "        # Ignore file extensions\n",
    "        sims = [os.path.splitext(filename)[0] for filename in sims]\n",
    "    else:\n",
    "        # Process a user-specified list\n",
    "        if not isinstance(sims, list):\n",
    "            sims = [sims]\n",
    "        # Ensure all inputs are strings\n",
    "        assert all(isinstance(x, str) for x in sims)\n",
    "        # Ensure all inputs result in a valid simulation file\n",
    "        for sid in sims:\n",
    "            filename = os.path.join(directory, f\"{sid}.bin\")\n",
    "            assert os.path.exists(filename), f\"File not found: {filename}\"\n",
    "    # Processing simulations\n",
    "    for sim in sims:\n",
    "        toJSON(sim)\n",
    "\n",
    "\n",
    "# Main\n",
    "directory = \"data/cycle/\"\n",
    "sims = None\n",
    "\n",
    "export(directory, sims)\n",
    "print(\"Bye.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "85bf0e9c58eee383cf410aa2386a3c5163b13680be7e32b9f97c0a8ccc9ea0ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
